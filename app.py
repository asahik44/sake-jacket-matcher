import os
import streamlit as st
import streamlit.components.v1 as components
import pickle
import numpy as np
import torch
from sentence_transformers import SentenceTransformer, util
from transformers import BertTokenizer, BertForSequenceClassification
import torch.nn.functional as F
import traceback
import gc
import time
import json
import datetime
import uuid
from google.cloud import bigquery
from google.oauth2 import service_account

# ==========================================
# â˜…è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
DEBUG_MODE = False
APP_TITLE = "Sake Jacket Matcher"
APP_VERSION = "ver 1.2.6" # â˜…ã‚»ãƒƒã‚·ãƒ§ãƒ³IDå¯¾å¿œç‰ˆ
USE_LOGIC_MODEL = False

# â˜…BigQueryã®è¨­å®š
BQ_TABLE_ID = "sake-app-logs.sake_app_logs.search_logs" 

GENRE_ORDER = [
    "ãƒ“ãƒ¼ãƒ«", "æµ·å¤–ãƒ“ãƒ¼ãƒ«", "åœ°ãƒ“ãƒ¼ãƒ«ãƒ»ã‚¯ãƒ©ãƒ•ãƒˆãƒ“ãƒ¼ãƒ«",
    "ã‚¦ã‚¤ã‚¹ã‚­ãƒ¼", "ãƒ¯ã‚¤ãƒ³", "èµ¤ãƒ¯ã‚¤ãƒ³", "ç™½ãƒ¯ã‚¤ãƒ³", "ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒªãƒ³ã‚°ãƒ¯ã‚¤ãƒ³", "ã‚·ãƒ£ãƒ³ãƒ‘ãƒ³",
    "æ—¥æœ¬é…’", "ç„¼é…", "èŠ‹ç„¼é…", "éº¦ç„¼é…", "ç±³ç„¼é…",
    "ãƒªã‚­ãƒ¥ãƒ¼ãƒ«", "ã‚¸ãƒ³ãƒ»ã‚¯ãƒ©ãƒ•ãƒˆã‚¸ãƒ³", "æ¢…é…’",
    "ãƒãƒ³ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«","ã‚µãƒ¯ãƒ¼ã®ç´ ãƒ»å‰²æ"
]

st.set_page_config(
    page_title="Sake Jacket Matcher | AIã§ç›´æ„Ÿçš„ã«ã‚¸ãƒ£ã‚±è²·ã„", 
    layout="wide",
    page_icon="https://sake-jaket.herahin.net/sake_favicon.png"
)
st.sidebar.caption(f"App Version: {APP_VERSION}")

# ==========================================
# â˜…ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®ç”Ÿæˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼è­˜åˆ¥ç”¨ï¼‰
# ==========================================
if "session_id" not in st.session_state:
    # ã¾ã IDãŒãªã„å ´åˆï¼ˆã‚¢ã‚¯ã‚»ã‚¹ã—ãŸç¬é–“ï¼‰ã€ãƒ©ãƒ³ãƒ€ãƒ ãªUUIDã‚’ç™ºè¡Œã—ã¦ä¿å­˜
    st.session_state.session_id = str(uuid.uuid4())

# ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šã‚µã‚¤ãƒ‰ãƒãƒ¼ã«IDã‚’è¡¨ç¤ºï¼ˆæœ¬ç•ªã§ã¯æ¶ˆã—ã¦ã‚‚OKï¼‰
if DEBUG_MODE:
    st.sidebar.text(f"Session ID: {st.session_state.session_id}")


# --- BigQueryãƒ­ã‚°é€ä¿¡é–¢æ•°ï¼ˆä¿®æ­£ç‰ˆï¼‰ ---
def log_to_bigquery(query_text, genres, min_p, max_p):
    """
    æ¤œç´¢ãƒ­ã‚°ã‚’BigQueryã«é€ä¿¡ã™ã‚‹é–¢æ•°ï¼ˆç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ç‰ˆï¼‰
    """
    if not query_text: return 
    
    # â˜…å¤‰æ›´ç‚¹: st.secrets ã§ã¯ãªã os.environ ã‹ã‚‰ç›´æ¥èª­ã‚€
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã§ import os ã—ã¦ã„ã‚‹ã®ã§ã€ã“ã“ã¯ãã®ã¾ã¾ os.environ ãŒä½¿ãˆã¾ã™
    json_str = os.environ.get("GCP_JSON")

    if not json_str:
        # ç’°å¢ƒå¤‰æ•°ã«ã‚‚ãªã„å ´åˆã¯ã€å¿µã®ãŸã‚ st.secrets ã‚‚è¦‹ã¦ã¿ã‚‹ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
        try:
            if "GCP_JSON" in st.secrets:
                json_str = st.secrets["GCP_JSON"]
        except Exception:
            pass
    
    # ãã‚Œã§ã‚‚ãªã‘ã‚Œã°ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã—ã¦çµ‚äº†
    if not json_str:
        if DEBUG_MODE: st.sidebar.error("âš ï¸ Secret 'GCP_JSON' not found in env.")
        return

    try:
        # æ–‡å­—åˆ—ã®JSONã‚’è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
        key_dict = json.loads(json_str)
        
        creds = service_account.Credentials.from_service_account_info(key_dict)
        client = bigquery.Client(credentials=creds, project=key_dict["project_id"])

        rows_to_insert = [{
            "timestamp": datetime.datetime.now().isoformat(),
            "session_id": st.session_state.session_id,
            "query": query_text,
            "genres": ",".join(genres) if genres else "All",
            "min_price": min_p,
            "max_price": max_p
        }]

        errors = client.insert_rows_json(BQ_TABLE_ID, rows_to_insert)
        
        if errors:
            if DEBUG_MODE: st.sidebar.error(f"BQ Error: {errors}")
            print(f"BQ Insert Error: {errors}")
        else:
            if DEBUG_MODE: st.sidebar.success("Log saved!")
            print(f"Log saved: {query_text} (ID: {st.session_state.session_id})")

    except Exception as e:
        print(f"BigQuery Connection Error: {e}")
        if DEBUG_MODE: st.sidebar.error(f"BQ Exception: {e}")

st.markdown("""
<style>
    header {visibility: visible !important; background-color: transparent !important;}
    footer {visibility: hidden !important; display: none !important;}
    div[data-testid="stDecoration"] {visibility: hidden; display: none;}
    div[class*="viewerBadge"] {visibility: hidden !important; display: none !important;}
    .viewerBadge_container__1QSob {display: none !important;}
    div[data-testid="stImage"] img { height: 200px; object-fit: contain; width: 100%; }
</style>
""", unsafe_allow_html=True)

# --- ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_all_models():
    try:
        with open('sake_database.pkl', 'rb') as f:
            db_data = pickle.load(f)
    except FileNotFoundError:
        st.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹(sake_database.pkl)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

    try:
        clip_model = SentenceTransformer('sentence-transformers/clip-ViT-B-32-multilingual-v1')
        raw_vectors = np.concatenate([item['vector'] for item in db_data], axis=0)
        all_vectors_tensor = torch.tensor(raw_vectors).float().cpu()
        del raw_vectors
        gc.collect()
    except Exception as e:
        st.error(f"CLIPãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    raw_genres = list(set([item.get('genre', 'ãã®ä»–') for item in db_data]))
    sorted_genres = sorted(raw_genres, key=lambda x: GENRE_ORDER.index(x) if x in GENRE_ORDER else 999)
    
    intent_tk, intent_md, genre_tk, genre_md = None, None, None, None
    has_logic_model = False
    
    result = {
        "db": db_data,
        "clip": clip_model,
        "vectors": all_vectors_tensor,
        "genres": sorted_genres,
        "intent_tk": intent_tk, 
        "intent_md": intent_md, 
        "genre_tk": genre_tk, 
        "genre_md": genre_md, 
        "has_logic_model": has_logic_model
    }
    gc.collect()
    return result

models = load_all_models()
if not models: st.stop()

# --- ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é–¢æ•° ---
def mmr_sort(query_vec, candidate_vectors_tensor, candidate_items, top_k=12, diversity=0.8):
    try:
        PRE_FILTER_K = 2000 
        query_tensor = torch.tensor(query_vec).float().cpu()
        if query_tensor.dim() == 1: query_tensor = query_tensor.unsqueeze(0)
        
        all_sims = util.cos_sim(query_tensor, candidate_vectors_tensor)[0]
        
        if len(candidate_items) > PRE_FILTER_K:
            top_indices = torch.argsort(all_sims, descending=True)[:PRE_FILTER_K]
            candidate_vectors_tensor = candidate_vectors_tensor[top_indices]
            candidate_items = [candidate_items[i] for i in top_indices.tolist()]
            sims_to_query = all_sims[top_indices]
        else:
            sims_to_query = all_sims

        selected_indices = []
        candidate_indices = list(range(len(candidate_items)))
        
        for _ in range(min(len(candidate_items), top_k)):
            best_mmr_score = -float('inf')
            best_idx = -1
            for idx in candidate_indices:
                similarity_to_query = sims_to_query[idx].item()
                if selected_indices:
                    selected_vecs = candidate_vectors_tensor[selected_indices]
                    current_vec = candidate_vectors_tensor[idx].unsqueeze(0)
                    sim_to_selected = util.cos_sim(current_vec, selected_vecs)
                    max_similarity_to_selected = torch.max(sim_to_selected).item()
                else:
                    max_similarity_to_selected = 0
                mmr_score = (1 - diversity) * similarity_to_query - diversity * max_similarity_to_selected
                if mmr_score > best_mmr_score:
                    best_mmr_score = mmr_score
                    best_idx = idx
            selected_indices.append(best_idx)
            candidate_indices.remove(best_idx)
        return [candidate_items[i] for i in selected_indices], [sims_to_query[i].item() for i in selected_indices]
    except Exception as e:
        st.error(f"MMR Error: {e}")
        return [], []

# --- æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³æœ¬ä½“ ---
def search_engine(original_query, selected_genres, min_p, max_p, mode="visual", logic_mode="A", progress_bar=None, status_text=None):
    ai_message = ""
    search_genres = []
    
    if progress_bar: progress_bar.progress(10)
    if status_text: status_text.text("ğŸ¤” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è§£æä¸­...")
    
    try:
        if mode == "visual" and ("C" in logic_mode or "D" in logic_mode):
            query_for_clip = f"ã€Œ{original_query}ã€ã¨ã„ã†é›°å›²æ°—ã®ãŠé…’ã®ãƒœãƒˆãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³ã€‚ Package design of sake bottle with the vibe of {original_query}."
        else:
            query_for_clip = original_query

        if progress_bar: progress_bar.progress(30)
        if status_text: status_text.text("ğŸ¨ ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ä¸­...")

        if selected_genres:
            search_genres = selected_genres
        else:
            search_genres = [] 

        query_vec = models["clip"].encode(query_for_clip, convert_to_tensor=True).float().cpu().numpy()
        if query_vec.ndim == 1: query_vec = query_vec[None, :] 
        
        if progress_bar: progress_bar.progress(50)
        if status_text: status_text.text("ğŸ· ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å€™è£œã‚’æŠ½å‡ºä¸­...")

        valid_indices = []
        for i, item in enumerate(models["db"]):
            if search_genres and item.get('genre') not in search_genres: continue
            if not (min_p <= item['price'] <= max_p): continue
            valid_indices.append(i)
            
        if not valid_indices: 
            return [], ai_message
        
        target_vectors_tensor = models["vectors"][valid_indices]
        candidate_items = [models["db"][i] for i in valid_indices]

        if progress_bar: progress_bar.progress(70)
        if status_text: status_text.text(f"ğŸš€ {len(candidate_items)}ä»¶ã®ä¸­ã‹ã‚‰ãƒ™ã‚¹ãƒˆãƒãƒƒãƒã‚’é¸å®šä¸­...")

        if mode == "visual" and ("B" in logic_mode or "D" in logic_mode):
            results, raw_scores = mmr_sort(query_vec, target_vectors_tensor, candidate_items, top_k=12, diversity=0.8)
        else:
            q_tensor = torch.tensor(query_vec).float().cpu()
            scores = util.cos_sim(q_tensor, target_vectors_tensor)
            scores = scores[0] 
            sorted_args = torch.argsort(scores, descending=True)
            results = []
            raw_scores = []
            for i in range(min(12, len(sorted_args))):
                idx = sorted_args[i].item()
                results.append(candidate_items[idx])
                raw_scores.append(scores[idx].item())

        if progress_bar: progress_bar.progress(100)
        if status_text: status_text.text("âœ¨ å®Œäº†ï¼")
        time.sleep(0.5) 

        if raw_scores:
            max_s = max(raw_scores)
            min_s = min(raw_scores)
            normalized_scores = []
            if max_s == min_s:
                normalized_scores = [0.99] * len(raw_scores)
            else:
                for s in raw_scores:
                    norm = (s - min_s) / (max_s - min_s)
                    scaled = 0.70 + (norm * 0.29)
                    normalized_scores.append(scaled)
        else:
            normalized_scores = []

        final_results = []
        for item, score in zip(results, normalized_scores):
            item['match_score'] = score
            final_results.append(item)

        final_results.sort(key=lambda x: x['match_score'], reverse=True)
            
        return final_results, ai_message

    except Exception as e:
        st.error(f"ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        st.code(traceback.format_exc())
        return [], "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼"

# --- UIæ§‹ç¯‰ ---
st.title(f"ğŸ¾ {APP_TITLE}")
st.caption(f"Released: {APP_VERSION}") 

st.sidebar.header("Search Mode")
mode_key = "visual"

st.sidebar.divider()
st.sidebar.header("Filters")
user_genres = st.sidebar.multiselect("ã‚¸ãƒ£ãƒ³ãƒ«å›ºå®š", options=models["genres"])
price_range = st.sidebar.slider("ä¾¡æ ¼å¸¯", 0, 100000, (0, 100000), 1000, format="Â¥%d")

logic_mode = "B: MMR (å¤šæ§˜æ€§é‡è¦–)"

col1, col2 = st.columns([3, 1], vertical_alignment="bottom")
with col1:
    placeholder = "ä¾‹ï¼šã‚µã‚¤ãƒãƒ¼ãƒ‘ãƒ³ã‚¯ãªå¤œ,æ£®ã®ä¸­ã§èª­æ›¸,åˆæ‹ã®å‘³..." 
    query = st.text_input("ã©ã‚“ãªé›°å›²æ°—ã®ãŠé…’ãŒã„ã„ï¼Ÿ", placeholder=placeholder).strip()
with col2:
    search_btn = st.button("Digã‚‹", type="primary", use_container_width=True)

if query or search_btn:
    st.query_params.from_dict({"q": query})

    # â˜…ä¿®æ­£ï¼šé‡è¤‡é€ä¿¡é˜²æ­¢ï¼ˆæ™‚é–“ ï¼‹ æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã®ä¸€è‡´ãƒã‚§ãƒƒã‚¯ï¼‰
    if "last_log_time" not in st.session_state:
        st.session_state.last_log_time = 0.0
    if "last_logged_query" not in st.session_state:
        st.session_state.last_logged_query = ""
    
    current_time = time.time()
    
    # æ¡ä»¶: ã€Œ5ç§’ä»¥ä¸ŠçµŒéã—ã¦ã„ã‚‹ã€ ã¾ãŸã¯ ã€Œæ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ãŒå‰å›ã¨é•ã†ã€ å ´åˆã®ã¿é€ã‚‹
    is_time_passed = (current_time - st.session_state.last_log_time > 5.0)
    is_new_query = (query != st.session_state.last_logged_query)

    if is_time_passed or is_new_query:
        # å…ˆã«ã‚¹ãƒ†ãƒ¼ãƒˆã‚’æ›´æ–°ï¼ˆãƒ­ãƒƒã‚¯ï¼‰ã—ã¦ã€äºŒé‡é€ä¿¡ã‚’é˜²ã
        st.session_state.last_log_time = current_time
        st.session_state.last_logged_query = query
        
        # ãã®å¾Œã«é€ä¿¡å‡¦ç†
        log_to_bigquery(query, user_genres, price_range[0], price_range[1])
    else:
        if DEBUG_MODE: st.sidebar.warning("âš ï¸ Skipping duplicate log")

    st.divider()
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    with st.spinner('AIãŒè„³ã¿ããƒ•ãƒ«å›è»¢ä¸­...'):
        results, message = search_engine(query, user_genres, price_range[0], price_range[1], mode=mode_key, logic_mode=logic_mode, progress_bar=progress_bar, status_text=status_text)
    
    time.sleep(0.2)
    progress_bar.empty()
    status_text.empty()
    
    # ...ï¼ˆä»¥ä¸‹åŒã˜ãªã®ã§çœç•¥ã€ã‚‚ã—ã‚³ãƒ”ãƒ¼ãƒŸã‚¹ãŒä¸å®‰ãªã‚‰å…ƒã®ã¾ã¾ã§ã‚‚UIéƒ¨åˆ†ã¯å‹•ãã«å½±éŸ¿ã—ã¾ã›ã‚“ï¼‰
    if message: st.caption(message)
    
    if results:
        cols = st.columns(3)
        for i, item in enumerate(results):
            with cols[i % 3]:
                with st.container(height=450, border=True): 
                    if item.get('image_url'): st.image(item['image_url'], use_container_width=True)
                    else: st.text("No Image")
                    
                    st.progress(item['match_score'], text=f"Match: {int(item['match_score']*100)}%")
                    st.write(f"**{item['name'][:30]}**")
                    price_str = f"Â¥{item['price']:,}"
                    st.caption(f"ğŸ· {item.get('genre')} | ğŸ’° {price_str}")
                    st.link_button("æ¥½å¤©ã§è¦‹ã‚‹ â¤", item['url'], use_container_width=True)
    else:
        if message != "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼":
            st.warning("âš ï¸ çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šåˆ©ç”¨è¦ç´„ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ ---
with st.sidebar.expander("â„¹ï¸ åˆ©ç”¨è¦ç´„ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼"):
    st.markdown("""
    **1. ãƒ‡ãƒ¼ã‚¿ã®åé›†ã«ã¤ã„ã¦**
    å½“ã‚¢ãƒ—ãƒªã§ã¯ã€ã‚µãƒ¼ãƒ“ã‚¹å‘ä¸Šã®ãŸã‚ä»¥ä¸‹ã®æƒ…å ±ã‚’å–å¾—ãƒ»ä¿å­˜ã—ã¾ã™ã€‚
    - å…¥åŠ›ã•ã‚ŒãŸæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€é¸æŠã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿æƒ…å ±
    - ã‚µã‚¤ãƒˆã®åˆ©ç”¨çŠ¶æ³ï¼ˆGoogle Analyticsã‚’ä½¿ç”¨ï¼‰
    - ã‚»ãƒƒã‚·ãƒ§ãƒ³è­˜åˆ¥å­ï¼ˆå€‹äººã‚’ç‰¹å®šã—ãªã„ãƒ©ãƒ³ãƒ€ãƒ ãªIDï¼‰
    
    **2. Google Analyticsã®ä½¿ç”¨**
    å½“ã‚¢ãƒ—ãƒªã¯ã‚¢ã‚¯ã‚»ã‚¹è§£æã®ãŸã‚ã«Google Analyticsã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿åé›†ã®ãŸã‚ã«Cookieã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€å€‹äººã‚’ç‰¹å®šã™ã‚‹æƒ…å ±ã¯å«ã¾ã‚Œã¾ã›ã‚“ã€‚
    
    **3. å…è²¬äº‹é …**
    - æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã«ã¯ã€å€‹äººåã‚„é›»è©±ç•ªå·ãªã©ã®**å€‹äººæƒ…å ±ã¯çµ¶å¯¾ã«å…¥åŠ›ã—ãªã„ã§ãã ã•ã„**ã€‚
    - å½“ã‚¢ãƒ—ãƒªã®åˆ©ç”¨ã«ã‚ˆã‚Šç”Ÿã˜ãŸæå®³ã«ã¤ã„ã¦ã€é–‹ç™ºè€…ã¯ä¸€åˆ‡ã®è²¬ä»»ã‚’è² ã„ã¾ã›ã‚“ã€‚
    - å•†å“æƒ…å ±ã¯æ¥½å¤©APIç­‰ã‚’åˆ©ç”¨ã—ã¦ã„ã¾ã™ãŒã€æœ€æ–°ã®ä¾¡æ ¼ã‚„åœ¨åº«çŠ¶æ³ã¯ãƒªãƒ³ã‚¯å…ˆã®åº—èˆ—ã§ã”ç¢ºèªãã ã•ã„ã€‚
    
    **4. ãŠå•ã„åˆã‚ã›**
    ä¸å…·åˆã‚„å‰Šé™¤ä¾é ¼ã¯ [é–‹ç™ºè€…ã®X (Twitter)](https://x.com/asahirk44) ã¾ã§ã”é€£çµ¡ãã ã•ã„ã€‚
    """)